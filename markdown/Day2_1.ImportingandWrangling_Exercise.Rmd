---
title: "Importing and Wrangling"
output: 
  html_document:
    highlight: tango
    toc: true
    toc_float:
      collapsed: true
---


Please go to Session on the RStudio Menu, and click on 'Restart R and Clear Output'.


Tutorial adapted from:
https://rafalab.github.io/dsbook/


# IMPORTING DATA

## Importing data from electronic spreadsheets 

### The working directory

We recommend only using relative paths in your code. The reason is that full paths are unique to your computer and you want your code to be portable. 
You can get the full path of your working directory without writing it out explicitly by using the `getwd` function.

The current directory should be `/home/rstudio/markdown` If you need to change your working directory, you can use the function `setwd`


```{r, eval=FALSE}
getwd()
```

### Identify spreadsheet you want to load

Use the `dir` function to list spreadsheets available in the `/home/rstudio/inst/extdata` folder. Be careful of relative paths! 
Use `../` for the parent (`/home/rstudio`) directory, and then access the `inst/extdata` folder.

```{r}
dir(path="../inst/extdata")
```


### Using the readr package

The __readr__ library includes functions for reading data stored in text file spreadsheets into R. __readr__ is part of the __tidyverse__ package. 
Load all the tidyverse packages at once by installing and loading the __tidyverse__ package.

```{r}
library(tidyverse)
```

And then use `read_csv` to read-in `murders.csv`

```{r}
dat<-read.csv("../inst/extdata/murders.csv")
head(dat)
```


## Importing data via datasets available through loaded packages

You also import the same dataset directly through the `dslabs` package

```{r}
library(dslabs)
data("murders")
head(murders)
```
 


# Wrangling 

We will be using data frames or _tibbles_ for the majority of these exercises. We will focus on a specific data format referred to as _tidy_ and on specific collection of packages that are particularly helpful for working with _tidy_ data that are part of _tidyverse_.

## Tidy data {#tidy-data}

We say that a data table is in  _tidy_ format if each row represents one observation and columns represent the different variables available for each of these observations. The `murders` dataset is an example of a tidy data frame.

```{r}
head(murders)
```

Each row represent a state with each of the five columns providing a different variable related to these states: name, abbreviation, region, population, and total murders.


## Tidying/ manipulating tibbles

The __dplyr__ package from the __tidyverse__ introduces functions that perform some of the most common operations when working with __dataframe__ and uses names for these functions that are relatively easy to remember. For instance, to change the data table by adding a new column, we use `mutate`.  To filter the data table to a subset of rows, we use `filter`. Finally, to subset the data by selecting specific columns, we use `select`.

### Adding a column with `mutate`

The first task is to add the murder rates to our murders data frame.  The function `mutate`  takes the data frame as a first argument and the name and values of the variable as a second argument. So, to add murder rates, we use:
 
```{r, message=FALSE}
murders <- mutate(murders, rate = total / population * 100000)
```

Notice that here we used `total` and `population` inside the function, which are objects that are **not** defined in our workspace. This is one of __dplyr__'s main features. Functions in this package, such as `mutate`, know to look for variables in the data frame provided in the first argument. 

We can see that the new column is added:

```{r}
head(murders)
```

Although we have overwritten the original `murders` object, this does not change the object that loaded with `data(murders)`. If we load the `murders` data again, the original will overwrite our mutated version.

### Subsetting with `filter`

Now suppose that we want to filter the data table to only show the entries for which the murder rate is lower than 0.71. To do this we use the `filter` function.

```{r}
filter(murders, rate <= 0.71)
```


### Selecting columns with `select`

Although our data table only has six columns, some data tables include hundreds. If we want to view just a few, we can use the __dplyr__ `select` function. In the code below we select three columns: 

```{r}
 select(murders, state, region, rate)
```


### The pipe: `%>%`

With __dplyr__ we can perform a series of operations, for example `select` and then `filter`, by sending the results of one function to another using what is called the _pipe operator_: `%>%`. 

Show three variables (state, region, rate) for states that have murder rates below 0.71. 

```{r}
murders %>% select(state, region, rate) %>% filter(rate <= 0.71)
```

In general, the pipe _sends_ the result of the left side of the pipe to be the first argument of the function on the right side of the pipe. Functions in __tidyverse__ packages like __dplyr__ have this format and can be used easily with the pipe.



## Summarizing data

An important part of exploratory data analysis is summarizing data. The average and standard deviation are two examples of widely used summary statistics. More informative summaries can often be achieved by first splitting data into groups. In this section, we cover two new __dplyr__ verbs that make these computations easier: `summarize` and `group_by`. We learn to access resulting values using the `pull` function.  

### Summarize with `summarize` {#summarize}

The `summarize` function in __dplyr__ provides a way to compute summary statistics with intuitive and readable code. We continue with the murders dataset.

The following code computes the average and standard deviation of the population for the South region:

```{r}
data("murders")
s <- murders %>% 
  filter(region == "South") %>%
  summarize(average = mean(population), standard_deviation = sd(population))
s
```

This takes our original dataframe as input, filters it to keep only South region, and then produces a new summarized table with just the average and the standard deviation of populations We get to choose the names of the columns of the resulting table. For example, above we decided to use `average` and `standard_deviation`, but we could have used other names just the same.

Because the resulting table stored in `s` is a data frame, we can access the components with the accessor `$`:

```{r}
s$average
s$standard_deviation
```


### Extract variables with `pull`

When a data object is piped that object and its columns can also be accessed using the `pull` function. So instead of using the accessor `$`, we do the following

```{r}
avg<-murders %>% 
  filter(region == "South") %>%
  summarize(average = mean(population), standard_deviation = sd(population)) %>% 
  pull(average)
```

which is now a numeric:

```{r}
class(avg)
```

### Group then summarize with `group_by` {#group-by}

A common operation in data exploration is to first split data into groups and then compute summaries for each group. For example, we may want to compute the average and standard deviation for all regions separately. The `group_by` function helps us do this. 

```{r}
murders %>% group_by(region)
```

The result does not look very different from `murders`. Using the `summarize` function below applies the summarization to each group separately.

```{r}
murders %>% 
  group_by(region) %>%
  summarize(average = mean(population), standard_deviation = sd(population))
```



### Sorting data frames  with `arrange` 

When examining a dataset, it is often convenient to sort the table by the different columns. For ordering entire tables, the __dplyr__ function `arrange` is useful. For example, here we order the states by population size:

```{r}
murders %>%
  arrange(population) %>%
  head()
```

Note that the default behavior is to order in ascending order. To sort the table in descending order:

```{r}
murders %>% 
  arrange(desc(population)) 
```


## Reshaping data frames

### Longer

`pivot_longer()` makes datasets __longer__ by increasing the number of rows and decreasing the number of columns. The following sections show how to use `pivot_longer()` for a wide range of realistic datasets.

The `relig_income` dataset stores counts based on a survey which (among other things) asked people about their religion and annual income:

```{r}
data("relig_income")
head(relig_income)
```

This dataset contains three variables:

* `religion`, stored in the rows,
* `income` spread across the column names, and 
* `count` stored in the cell values. 

To tidy it we use `pivot_longer()`:

```{r}
relig_income %>% 
  pivot_longer(!religion, names_to = "income", values_to = "count")
```

* The first argument is the dataset to reshape, `relig_income`.

* The second argument describes which columns need to be reshaped. In this 
  case, it's every column apart from `religion`.

* The `names_to` gives the name of the variable that will be created from
  the data stored in the column names, i.e. `income`.
  
* The `values_to` gives the name of the variable that will be created from
  the data stored in the cell value, i.e. `count`.
  
### Wider

`pivot_wider()` is the opposite of `pivot_longer()`: it makes a dataset __wider__ by increasing the number of columns and decreasing the number of rows. 


## Joining tables with `left_join`


The information we need for a given analysis may not be just in one table. Suppose we want to explore the relationship between population size for US states and electoral votes. We have the population size in this table:

```{r, warning=FALSE, message=FALSE}
data(murders)
head(murders)
```

and electoral votes in this one:

```{r}
data(polls_us_election_2016)
head(results_us_election_2016)
```

The _join_ functions in the __dplyr__ package make sure that the tables are combined so that matching rows are together. The general idea is that one needs to identify one or more columns that will serve to match the two tables. Then a new table with the combined information is returned. 

```{r}
new_data <- left_join(murders, results_us_election_2016, by = "state") %>%
  select(-others) 
head(new_data)
```



## Converting to tibble

The print method for tibbles is more readable than that of a data frame. Compare the outputs of the __dataframe__ and __tibble__.

```{r}
data("murders")
class(murders)
murders

murders<-as_tibble(murders)
class(murders)
murders
```
